# ðŸŽµ InstruNet AI  
### Multi-Instrument Audio Intelligence Platform  

---

## ðŸŒ Live Demo

ðŸ”— **Live Application:**  
https://your-live-demo-link.com  



---

## ðŸš© Problem Statement

Modern audio analysis systems struggle with:

- Multi-instrument detection in mixed audio
- Lack of interpretability in AI predictions
- No structured analytics dashboards
- No exportable business reports
- Limited scalability for production systems

There is a need for a production-ready AI platform capable of:

- Multi-label instrument classification
- Visual analytics and explainability
- Exportable JSON & PDF reports
- Premium business workflows
- Scalable deep learning architecture

---

## ðŸŽ¯ Purpose of the Project

InstruNet AI was built to create a deployable, real-world AI system that:

- Detects multiple musical instruments from raw audio
- Uses CNN-based deep learning on Mel-Spectrogram features
- Provides an interactive analytics dashboard
- Generates professional PDF and JSON reports
- Implements premium access logic for business scenarios

---

## ðŸ“Œ Project Overview

InstruNet AI processes uploaded WAV files through the following pipeline:

1. Audio â†’ Mel-Spectrogram transformation  
2. CNN-based multi-label prediction  
3. Probability aggregation  
4. Dashboard visualization  
5. Report generation  

The deployed demo includes:

- ðŸ” Sign-in / Login system
- ðŸŽ§ Audio upload & processing
- ðŸ§  CNN confidence scoring
- ðŸ“Š Interactive analytics dashboard
- ðŸ“„ Downloadable PDF reports
- ðŸ“¦ JSON export
- â­ Premium watermark-free mode

---

## ðŸ§  Tech Stack

### AI & Backend
- Python
- TensorFlow / Keras
- Librosa

### Visualization
- Matplotlib
- Mel-Spectrogram analysis
- Timeline probability graphs
- Pie charts
- Frequency band distribution

### Frontend & Deployment
- Python
- Streamlit

### Reporting
- JSON export
- Professional PDF generation

---

## âœ¨ Core Features

### ðŸ” Authentication
- Secure login / sign-in
- Premium feature toggle
- Watermark removal for premium users

### ðŸŽ§ Audio Intelligence
- WAV file upload
- Multi-label instrument detection
- CNN confidence scoring

### ðŸ“Š Analytics Dashboard
- Instrument probability timeline
- Audio waveform visualization
- Mel-Spectrogram display
- Frequency band distribution analysis
- Interactive pie chart
- Prediction analysis summary
- Dominant instrument highlight

### ðŸ“„ Reporting System
- JSON export
- Professional PDF download
- Premium watermark-free reporting

---

## ðŸŽ¼ Supported Instruments

- ðŸŽ¶ Flute  
- ðŸŽ¸ Guitar  
- ðŸŽ¹ Piano  
- ðŸŽ» Violin  

*(Scalable architecture for additional instruments)*

---

## ðŸ§¾ Model Card

| Attribute | Details |
|------------|----------|
| Model Type | Convolutional Neural Network (CNN) |
| Input | 128 Ã— 128 Mel-Spectrogram |
| Output | Multi-label probabilities |
| Activation | Sigmoid |
| Loss Function | Binary Crossentropy |
| Optimizer | Adam |
| Evaluation Accuracy | ~85% |
| Training Data | Custom labeled WAV dataset |

---

## ðŸ— CNN Architecture

```text
Input (128x128x1)
â†“
Conv2D (32 filters) + ReLU
â†“
MaxPooling
â†“
Conv2D (64 filters) + ReLU
â†“
MaxPooling
â†“
Conv2D (128 filters) + ReLU
â†“
Flatten
â†“
Dense (128) + ReLU
â†“
Dropout
â†“
Dense (4) + Sigmoid
```

**Why Sigmoid?**  
Because this is a multi-label classification problem where multiple instruments can exist simultaneously.

---

## ðŸ“Š Dashboard Features

- Instrument Probability Timeline  
- CNN Confidence Indicator  
- Audio Waveform Visualization  
- Mel-Spectrogram Representation  
- Frequency Band Energy Distribution  
- Interactive Pie Chart  
- Dominant Instrument Highlight  
- Premium Export Controls  

---

## ðŸ“¦ Example JSON Output

```json
{
  "report": "InstruNet AI Analysis Report",
  "timestamp": "2/22/2026, 11:28:54 AM",
  "instrument": "Guitar",
  "confidence": 90.31613293826148,
  "health": "Healthy",
  "condition": "Excellent resonance with clear harmonic profile.",
  "intensity": 85.42309722468103,
  "developer": "Sai Nikith"
}
```

---

## ðŸ’¼ Business Use Cases

- ðŸŽ¼ Music production studios  
- ðŸŽµ Audio catalog tagging systems  
- ðŸ“Š Streaming platform analytics  
- ðŸŽ“ AI-powered music learning platforms  
- ðŸ” Audio forensics  
- ðŸ¤– Smart content moderation systems  

---

## ðŸš€ Installation (Local Development)

```bash
git clone https://github.com/sainikith07/Musical_Intrument_Predictor.git
cd Musical_Intrument_Predictor
pip install -r requirements.txt
streamlit run app.py
```

---

## ðŸ›£ Roadmap

- Add 10+ instrument classes
- Expand dataset diversity
- Real-time microphone detection
- Mobile app integration

---

## ðŸ¤ Contribution

Contributions are welcome.

1. Fork the repository
2. Create a feature branch
3. Submit a pull request

---

## ðŸ‘¨â€ðŸ’» Author

**Sai Nikith**  
AI Engineer | Audio Intelligence Developer  

- ðŸ”— GitHub: [sainikith07](https://github.com/sainikith07)  
- ðŸ”— LinkedIn: [Sai Nikith Kaleru](https://www.linkedin.com/in/sai-nikith-kaleru/)  
- ðŸ“§ Email: sainikith04@gmail.com   

---

## ðŸ’¬ Support

For collaborations, business inquiries, or improvements:

Connect via LinkedIn.

---

## â–¶ How To Run

1. Login to the platform  
2. Upload WAV audio file  
3. View detection results  
4. Analyze dashboard insights  
5. Download JSON or PDF report  
6. Upgrade to premium for watermark-free export  

---

## â­ Project Highlights

âœ” Multi-label instrument detection  
âœ” Real-time probability visualization  
âœ” Professional reporting system  
âœ” Premium business logic integration  
âœ” Scalable CNN architecture  
âœ” Production-ready UI  

---

> InstruNet AI demonstrates how deep learning can be transformed from a research prototype into a business-ready intelligent audio analytics platform.
